---
title: Inference
description: Inference
---

import { ImageZoom } from "fumadocs-ui/components/image-zoom";

import NodeInference from "@/public/assets/screenshots/node-inference.png";

Inference is the process of applying a trained model to new data to make
predictions. In the context of the deepsirius platform, inference is the process
of applying a trained model to a new image to segment it.

<ImageZoom
  alt="Inference node and form."
  src={NodeInference}
  className="!my-0 rounded-sm"
  priority
/>
_Inference node connected to a network node with its form open on the side panel._

Below are the parameters that can be set in the inference form:

## Normalize images

If the images are not normalized, this option should be enabled. Normalizing
images is a common practice because it improves optimization during training. By
default, the network receives normalized images during training. Therefore,
inference in non normalized images will produce bad results.

## Probability map

The output is a probability map, where each channel "n" corresponds to the
probability of that voxel corresponding to the label "n". If the probability map
is not select will infer a label image where each voxel corresponds to the label
with probability higher or equal to 0.5.

## Padding size

Adds a 0-valued frame around the input image to ensure that boundary effects to
classification being done patchwise are mitigated.

## Patch size

Similar to Volume Padding, this parameter controls the amount of overlap between
patches sampled over the target image for inference. Lower values increase
classification speed at the cost of edge artifacts. In other words, it
determines how much edge will be thrown away when making the inference. We throw
it away because of an edge effect on each patch inside the image.
