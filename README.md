# DeepSirius UI

This is a web interface for the ssc-deepsirius package, which is a deep learning based tool for segmentation analysis of tomographic image data generated by the Sirius synchrotron at the National Synchrotron Light Laboratory (LNLS) in Campinas, Brazil.

The interface is meant to be used as a client for the ssc-deepsirius package, which is a python package that runs on demand on the cluster when the deepsirius-ui server creates a slurm job in the appropriate queue of data processing of the Sirius cluster.

Its logic is based on the ssc-deepsirius structure, which divides the workflow in three main independent steps:

1. **Dataset creation**: This steps consists in the creation of a dataset from a set of tomographic images. The dataset is a set of numpy arrays that are saved in a hdf5 file. This step is meant to be run only once for a given set of images, and the dataset can be used for multiple analysis. The dataset creation is done by the `create_dataset` and `augmented_dataset` function in the ssc-deepsirius package cli.

2. **Network training**: This step consists in the training of a deep learning model for the segmentation of the dataset created in the previous step. The training is done by the `train_model` and `finetune_model` functions in the ssc-deepsirius package cli.

3. **Inference**: This step consists in the segmentation of a set of tomographic images using the model trained in the previous step. The segmentation is done by the `run_inference` function in the ssc-deepsirius package cli.

These steps are meant to be run in sequence for a complete cycle of the deep learning process, but as the jobs associated with each step are independent and can take a long time to run, the user is able to run them independently, as long as the previous step has been run before without errors. This opens the possibility for the user to create more than one possible path of analysis, by creating more than one dataset, training more than one model with the same dataset of different training parameters, and running minferences with more than one model for different sets of images.

To accomplish this, the interface has a workflow view that allows the user to create and connect many components that represent the steps of the analysis. The user can create any number of components of each type, and connect them in any order, as long as the previous step is completed and the steps are in the right order (1 -> 2 -> 3).

When a component is created, it is added to the workflow view, and the user can click to activate it, which transforms the state of the component into a form that allows the user to input the parameters for the active component. When the user clicks the run button, the component sends the information to the server, which creates the slurm job and runs the analysis on the Sirius cluster. This changes the state of the client component, that now checks the server for the status of the job, and updates the state of the component accordingly. The changes in the workflow view and component states and connections are also reflected in the database, so that the user can close the browser and logging it again, and the workflow will be loaded with the same state as before so that when a job is in a running state, the user can check the status of the job when logging in again.

The interface also has a tree view that allows the user to navigate the filesystem of the Sirius cluster, and select the images that will be used for the dataset creation and inference components.

When accessing the web app on the browser, the user is presented with a login page, where the user can login with their credentials. The credentials are checked against the Sirius LDAP server, and if the user is authenticated, the user is redirected to the workflow selection view. If the user is not authenticated, the user is redirected to the login page again.

The workflow selection view is a list of workflows that the user has created in the interface. The user can create a new workflow by clicking the new workflow button, which redirects the user to the workflow view. The user can also click on an existing workflow to edit it, which redirects the user to the workflow view with the selected workflow loaded.

## Development

This interface was built using the [T3 Stack](https://create.t3.gg/), which is a set of tools and libraries that we use to build web applications at [T3](https://t3.gg/).

In this project, we chose to use [TypeScript](https://www.typescriptlang.org/) as our main language, [Next.js](https://nextjs.org) as our React framework, and [NextAuth.js](https://next-auth.js.org) for authentication. We also use [Prisma](https://prisma.io) to access our database, and [Tailwind CSS](https://tailwindcss.com) for styling.

For creating the workflow view of the client components, we use [React Flow](https://reactflow.dev/), which is a React library for creating flowcharts. The app main components are created as nodes in the flowchart, and the connections between represents connections beetween the representations of the components in the data processing workflow that will be triggered as a job in a cluster environment.

The state of the components is also reflected in the flowchart, so that the user can see the status of the components (and its jobs) in the workflow view and are managed by a [Zustand](https://zustand-demo.pmnd.rs/) store on the cliend with hooks that updates the state of the components in the flowchart and when necessary, updates the database and interacts with the server through [tRPC](https://trpc.io) queries and mutations.

_TRPC_ enables a type-safe API layer between the client and the server and managing state updates between them using hooks based in the powerful `useQuery` and `useMutation` from [TanStack Query](https://tanstack.com/query/latest). So the full state of the applications is a _Tug of war_ beetween the client store, the database state and the other server mutations.

### Run Locally

You can copy the `compose.registry.yaml` file from the [github repository](https://github.com/cnpem/deepsirius-ui) and pull the built app from the [github registry page](https://github.com/cnpem/deepsirius-ui/pkgs/container/cnpem%2Fdeepsirius-ui) and run it locally with:

```shell
   docker compose --file compose.registry.yaml --env-file ./apps/deepsirius-ui/.env up
```

Then, open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

Or you can build the app yourself and run it locally by running the docker container with:

```shell
   docker compose --env-file ./apps/deepsirius-ui/.env up --build
```

Then, open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

### Start development environment

To start the development environment, you should fill the apps .env files with the appropriate variables for each app torun by itsekf. There is a .env.example in the apps file that you can use as a template.

To run slurm jobs, the app service need to be able to connect via ssh to a slurm management node with the same credentials of the ldap client.

With these requirements satisfied, you can go to one of the apps base path
and start the development i.e:

```shell
   cd apps/deepsirius-ui
   pnpm run dev
```

Then, open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## License

This project is licensed under the terms of the GPL license version 3 or later.
